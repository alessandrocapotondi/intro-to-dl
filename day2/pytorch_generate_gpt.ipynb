{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0e6e42c-a2a3-4ba9-be85-056035147486",
   "metadata": {},
   "source": [
    "# IMDB movie review text generation\n",
    "\n",
    "Once you have fine-tuned your model you can test it interactively with this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa458fec-a1e9-4960-9a9f-c7f21d0a7b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "path_to_model = \"/scratch/project_462000450/data/mvsjober/gpt-imdb-model/checkpoint-65000/\"\n",
    "generator = pipeline(\"text-generation\", model=path_to_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a5ecc40-1c1d-4c9d-a41c-937bbbbaf025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_output(output):\n",
    "    for item in output:\n",
    "        text = item['generated_text']\n",
    "        text = text.replace(\"<br />\", \"\\n\")\n",
    "        print('-', text)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf677501-f93d-46b1-a618-0fb792cd44cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- This movie was not quite to great though with all the action and the plot and the special effects you will find in the video store. The movie wasn't much good though there was some very good acting. Also some pretty good CGI effects. This film\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = generator(\"This movie was\")\n",
    "print_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fb8536-887f-4fad-a0b3-190d1749a594",
   "metadata": {},
   "source": [
    "## Experiment with the generation strategy\n",
    "\n",
    "You can play with the text generation if you wish. Text generation strategies are discussed here: https://huggingface.co/docs/transformers/generation_strategies\n",
    "\n",
    "The `generator()` function has some parameters than can be tweaked:\n",
    "\n",
    "> max_new_tokens: the maximum number of tokens to generate. In other words, the size of the output sequence, not including the tokens in the prompt. As an alternative to using the output’s length as a stopping criteria, you can choose to stop generation whenever the full generation exceeds some amount of time. To learn more, check StoppingCriteria.\n",
    "> \n",
    "> num_beams: by specifying a number of beams higher than 1, you are effectively switching from greedy search to beam search. This strategy evaluates several hypotheses at each time step and eventually chooses the hypothesis that has the overall highest probability for the entire sequence. This has the advantage of identifying high-probability sequences that start with a lower probability initial tokens and would’ve been ignored by the greedy search.\n",
    "> \n",
    "> do_sample: if set to True, this parameter enables decoding strategies such as multinomial sampling, beam-search multinomial sampling, Top-K sampling and Top-p sampling. All these strategies select the next token from the probability distribution over the entire vocabulary with various strategy-specific adjustments.\n",
    "> \n",
    "> num_return_sequences: the number of sequence candidates to return for each input. This option is only available for the decoding strategies that support multiple sequence candidates, e.g. variations of beam search and sampling. Decoding strategies like greedy search and contrastive search return a single output sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6816b3f3-9a0f-4ca8-a7d9-d7962b0207fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- This movie was awful because it was poorly directed, terrible dialog in the title, and a lot of unnecessary and unnecessary background footage.\n",
      "\n",
      "Why do they keep making this movie? Why they should hire one actor at every movie they work on and hire someone? What is it about those two characters you could not care less about? \n",
      "\n",
      "OK seriously, so they hire one of the good actors, the other one is a cop and the others act like they think they can be some kind\n",
      "\n",
      "- This movie was awful because she was a little too far the part was the little girl in the background! and then the only time she ever did was when she looked at her mother and said \"Don't see that girl\" or whatever she said. she just kept repeating this and even less and just threw in an episode where the little girl was talking to the guy like \"I'm a big sister and want my boyfriend to get some coffee before I see her or something like that.\" I would have given the episode 8/\n",
      "\n",
      "- This movie was awful because of the bad dialog. All actors, actresses and director (as in it was from the same year i was born), I don't know how it gets good by the standards of the rest of the movies. I just hope all of the actors have the chance to do something.\n",
      "\n",
      "- This movie was awful because of the slow editing, and because of the terrible cast. That being said, I had some time to do the voice over. The whole thing looked like an hour and a half. \n",
      "\n",
      "The only reason I gave this one an Oscar is because of the music. I feel sorry for the actors, because this is horrible. They wasted so much time during it. And the only actor I have ever seen who played a voice over other than Jaffrey should have played the\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = generator(\"This movie was awful because\", num_return_sequences=4, max_new_tokens=100, do_sample=True)\n",
    "print_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df008ff8-cb03-488f-b643-4aa2314de52c",
   "metadata": {},
   "source": [
    "## Compare with the original model without fine-tuning\n",
    "\n",
    "We can also load the original `distilgpt2` model and see how it would have worked without fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ba1f550-970e-419a-aaff-d4e821bacc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_orig = pipeline(\"text-generation\", model='distilgpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4995c393-29ad-4df1-b01a-83cd85008297",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- This movie was awful because there was no sound.\n",
      "\n",
      "\n",
      "What was it like to have this movie in one hand?\n",
      "It looked like this was really bad.\n",
      "The soundtrack to the movie had a ton of strange, weird sounds, and there was some real weird noises or things. It seemed like the sound was actually all that different during that movie.\n",
      "So I was not impressed by the sound itself, so I just went through the first day and didn't see any such sound.\n",
      "The game was just\n",
      "\n",
      "- This movie was awful because I really don't have an idea what I could do. I had thought it'd work out and that's when I read this book. It has been a very nice little book, and definitely helps me to learn how it works so I just need to do the script again. I've got a lot of ideas in each part of the story, but I still haven't worked out it yet.\n",
      "\n",
      "\n",
      "This review's a must for me so keep checking out. If you're reading it\n",
      "\n",
      "- This movie was awful because it turned into an all-out affair. It went from a horrible one to an absolute disgrace. A little more because it wasn't the top five directors at all. But it was the top eight at all which makes it a fine choice.\n",
      "\n",
      "But I would definitely say some have made bad decisions about who made these directors, even when they weren't for the first time in my life, or maybe the movie had the best story and best movie, or a lot of people had had a\n",
      "\n",
      "- This movie was awful because of its portrayal of the man who lost his wife (he'd gone so far as to say that in the American movie ‒s early 20th Century Fox film, the man who's gone so far as to say that in the American film ‒s early 20th Century Fox film, the man who's gone so far as to say that in the American film‒s early 20th Century Fox film, the man who's gone so far as to say that in the American film�\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = generator_orig(\"This movie was awful because\", num_return_sequences=4, max_new_tokens=100, do_sample=True)\n",
    "print_output(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23aecd9-4a56-4b06-8a65-4fc43b0628d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
